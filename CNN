
import os
from tensorflow.keras.datasets import mnist
import tensorflow.compat.v1 as tf
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
tf.logging.set_verbosity(tf.compat.v1.logging.ERROR)
tf.disable_v2_behavior()
from sklearn.model_selection import train_test_split
import numpy as np
import random
import matplotlib.pyplot as plt
from time import time
import tensorflow as tf_v2 # 為了 tf.keras.utils.to_categorical 導入 v2 版本
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense
# Removed Flatten from import as we will use tf.reshape instead

# 將 numpy 陣列中的圖片和標籤順序打亂
def shuffer_images_and_labels(images, labels):
    shuffle_indices = np.random.permutation(np.arange(len(images)))
    shuffled_images = images[shuffle_indices]
    shuffled_labels = labels[shuffle_indices]
    return shuffled_images, shuffled_labels

# 將label從長度10的one hot向量轉換為0~9的數字
# 例：get_label(total_labels[0]) 獲取到total_labels中第一個標籤對應的數字
def get_label(label):
    # Assuming label is one-hot encoded
    if isinstance(label, np.ndarray) and label.ndim == 1:
        return np.argmax(label)
    # If label is a single integer
    return label

def show_image(image):
    # Assuming image is a flattened 784 array
    if image.shape == (784,):
        tmp = image.reshape(28, 28)
    else:
        tmp = image # Assuming image is already 28x28
    plt.imshow(tmp, cmap='gray') # Added cmap='gray' for better visualization
    # Display label if available (this function primarily for showing images, label comes from context)
    # plt.title(f"Label: {get_label(label)}") # This would require passing label as well
    plt.show()

# images：訓練集的feature部分
# labels：訓練集的label部分
# batch_size： 每次訓練的batch大小
# epoch_num： 訓練的epochs數
# shuffle： 是否打亂數據
def batch_iter(images,labels, batch_size, epoch_num, shuffle=True):

    data_size = len(images)

    num_batches_per_epoch = data_size // batch_size # 使用整數除法

    for epoch in range(epoch_num):
        # Shuffle the data at each epoch
        if shuffle:
            shuffle_indices = np.random.permutation(np.arange(data_size))

            shuffled_data_feature = images[shuffle_indices]
            shuffled_data_label   = labels[shuffle_indices]
        else:
            shuffled_data_feature = images
            shuffled_data_label = labels

        for batch_num in range(num_batches_per_epoch):   # batch_num取值0到num_batches_per_epoch-1
            start_index = batch_num * batch_size
            end_index = (batch_num + 1) * batch_size # 確保取到完整的 batch

            yield (shuffled_data_feature[start_index:end_index] , shuffled_data_label[start_index:end_index])


# 構建和訓練 FCN 模型 (為了比較保留此函數，但可能已在之前的程式碼中移除其呼叫)
def train_and_test_fcn(images_train, labels_train, images_test, labels_test,
                   images_validation, labels_validation):
    print("\n[-] Start training FCN model...")
    # Input layers (28*28*1)
    x = tf.placeholder(tf.float32, [None, 784], name="X")
    # 0-9 => 10 numbers
    y = tf.placeholder(tf.float32, [None, 10], name="Y")

    #FCN全連接神經網路層 - 由於您只保留了 train_and_test_cnn，這裡的 fcn_layer 函數可能沒有被呼叫到
    # 但為了完整性，如果需要 FCN 模型，這個函數及 fcn_layer 需要存在。
    def fcn_layer(inputs, input_dim, output_dim, activation=None):
        W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1))
        b = tf.Variable(tf.zeros([output_dim]))
        XWb = tf.matmul(inputs, W) + b
        if activation is None:
            outputs = XWb
        else:
            outputs = activation(XWb)
        return outputs

    # 2 Hidden layers
    h1 = fcn_layer(inputs=x,
                   input_dim=784,
                   output_dim=256,
                   activation=tf.nn.relu)
    h2 = fcn_layer(inputs=h1,
                   input_dim=256,
                   output_dim=64,
                   activation=tf.nn.relu)
    # Output layers
    forward = fcn_layer(inputs=h2,
                        input_dim=64,
                        output_dim=10,
                        activation=None)
    pred = tf.nn.softmax(forward)

    loss_function = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(logits=forward, labels=y))

    train_epochs = 20  # Train times
    batch_size = 100  # single batch train size
    learning_rate = 0.001  # learning rate

    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)

    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))

    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    startTime = time()

    sess = tf.Session()
    init = tf.global_variables_initializer()
    sess.run(init)

    # 用於儲存訓練結果的列表
    test_loss_history = []
    test_accuracy_history = []

    for epoch in range(train_epochs):
        for xs, ys in batch_iter(images_train, labels_train, batch_size, 1, shuffle=True):
            sess.run(optimizer, feed_dict={x: xs, y: ys})

        loss, acc = sess.run([loss_function, accuracy],
                             feed_dict={x: images_test, y: labels_test})

        # 儲存結果
        test_loss_history.append(loss)
        test_accuracy_history.append(acc)

        print(f"[+] {'%02d' % (epoch + 1)}th train:\tloss:", "{:.9f}".format(loss), "\taccuracy:", "{:.4f}".format(acc))

    duration = time() - startTime
    print("[+] Train finished successfully. It takes:", "{:.2f}s".format(duration))

    # 繪製訓練結果圖表
    plt.figure(figsize=(12, 5))

    # 繪製損失圖
    plt.subplot(1, 2, 1)
    plt.plot(range(1, train_epochs + 1), test_loss_history, label='Test Loss')
    plt.title('FCN Test Loss during Training')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    # 繪製準確度圖
    plt.subplot(1, 2, 2)
    plt.plot(range(1, train_epochs + 1), test_accuracy_history, label='Test Accuracy', color='green')
    plt.title('FCN Test Accuracy during Training')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()

    accu_test = sess.run(accuracy, feed_dict={x: images_test, y: labels_test})
    accu_validation = sess.run(accuracy, feed_dict={x: images_validation, y: labels_validation})
    return accu_test, accu_validation, test_loss_history, test_accuracy_history # 返回歷史記錄


# 構建和訓練 CNN 模型 (已修正 Flatten 層的輸入問題)
def train_and_test_cnn(images_train, labels_train, images_test, labels_test,
                       images_validation, labels_validation):
    print("\n[-] Start training CNN model...")

    # Input layers (28*28*1) - CNN 需要將輸入 reshape 為 4D 張量 (batch_size, height, width, channels)
    x = tf.placeholder(tf.float32, [None, 784], name="X")
    x_reshaped = tf.reshape(x, [-1, 28, 28, 1])
    # 0-9 => 10 numbers
    y = tf.placeholder(tf.float32, [None, 10], name="Y")

    # CNN 層
    conv1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(x_reshaped)
    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)
    conv2 = Conv2D(64, kernel_size=(3, 3), activation='relu')(pool1)
    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)

    # Explicitly ensure pool2 is a TensorFlow tensor before flattening
    # This can help in mixed TF1/TF2 environments when Keras layers are used
    # tf.identity() 創建一個與輸入具有相同類型和形狀的新張量，有時有助於確保張量在圖中的正確處理。
    # pool2_tensor = tf.identity(pool2) # Keep this line if needed for other purposes, but not strictly needed for reshape

    # Flatten 層
    # 將 4D 張量 (batch_size, height, width, channels) 展平為 (batch_size, height * width * channels)
    # 替換 Keras Flatten 層為 tf.reshape
    flattened_dim = int(pool2.shape[1] * pool2.shape[2] * pool2.shape[3]) # Calculate flattened dimension
    flatten = tf.reshape(pool2, [-1, flattened_dim]) # Use tf.reshape instead of Keras Flatten

    # 全連接層 (FCN) - 作為 CNN 的輸出層前的分類器
    dense1 = Dense(128, activation='relu')(flatten)
    # Output layers
    forward = Dense(10, activation=None)(dense1)
    pred = tf.nn.softmax(forward)

    loss_function = tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(logits=forward, labels=y))

    train_epochs = 20  # Train times
    batch_size = 100  # single batch train size
    learning_rate = 0.001  # learning rate

    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss_function)

    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))

    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

    startTime = time()

    sess = tf.Session()
    init = tf.global_variables_initializer()
    sess.run(init)

    # 用於儲存訓練結果的列表
    test_loss_history = []
    test_accuracy_history = []

    for epoch in range(train_epochs):
        for xs, ys in batch_iter(images_train, labels_train, batch_size, 1, shuffle=True):
            sess.run(optimizer, feed_dict={x: xs, y: ys})

        loss, acc = sess.run([loss_function, accuracy],
                             feed_dict={x: images_test, y: labels_test})

        # 儲存結果
        test_loss_history.append(loss)
        test_accuracy_history.append(acc)

        print(f"[+] {'%02d' % (epoch + 1)}th train:\tloss:", "{:.9f}".format(loss), "\taccuracy:", "{:.4f}".format(acc))

    duration = time() - startTime
    print("[+] Train finished successfully. It takes:", "{:.2f}s".format(duration))

    # 繪製訓練結果圖表
    plt.figure(figsize=(12, 5))

    # 繪製損失圖
    plt.subplot(1, 2, 1)
    plt.plot(range(1, train_epochs + 1), test_loss_history, label='Test Loss')
    plt.title('CNN Test Loss during Training')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()

    # 繪製準確度圖
    plt.subplot(1, 2, 2)
    plt.plot(range(1, train_epochs + 1), test_accuracy_history, label='Test Accuracy', color='green')
    plt.title('CNN Test Accuracy during Training')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()


    accu_test = sess.run(accuracy, feed_dict={x: images_test, y: labels_test})
    accu_validation = sess.run(accuracy, feed_dict={x: images_validation, y: labels_validation})
    return accu_test, accu_validation, test_loss_history, test_accuracy_history # 返回歷史記錄


# 劃分數據集並調用train_and_test測試和驗證 (這裡僅保留 hold_out，用於數據準備)
def hold_out(images, labels, train_percentage):
    X_train, X_test, Y_train, Y_test = train_test_split(images,
                                                        labels,
                                                        test_size=1 - train_percentage,
                                                        random_state=1,
                                                        stratify=labels)
    return X_train, Y_train, X_test, Y_test

# 交叉驗證函數 (為了提供一個完整的 CNN 訓練範例，保留了交叉驗證，但只使用 CNN 模型)
def cross_validation_cnn(images, labels, k, vali_images, vali_labels):
    print("\n[*] Performing Cross Validation (Using CNN model)")
    total_images = [[] for _ in range(10)]
    total_labels = [[] for _ in range(10)]

    for i in range(len(images)):
        index = get_label(labels[i])
        total_images[index].append(images[i])
        total_labels[index].append(labels[i])

    k_total_images = []
    k_total_labels = []
    for i in range(10):
        for j in range(k):
            start_index = int(j * len(total_images[i]) / k)
            end_index = int((j + 1) * len(total_images[i]) / k)
            k_total_images.append(total_images[i][start_index:end_index])
            k_total_labels.append(total_labels[i][start_index:end_index])

    tmp_accu_test = 0
    tmp_accu_vali = 0
    for idex in range(k):
        X_test_images = k_total_images[idex]
        Y_test_labels = k_total_labels[idex]

        X_train_images_list = []
        Y_train_labels_list = []
        for i in range(k):
            if i != idex:
                X_train_images_list.extend(k_total_images[i])
                Y_train_labels_list.extend(k_total_labels[i])

        f_X_train_images, f_Y_train_labels = np.array(X_train_images_list), np.array(Y_train_labels_list)
        X_test_images, Y_test_labels = np.array(X_test_images), np.array(Y_test_labels)

        print("[-] k = {}，當前第{}組為測試集".format(k, idex+1))
        # 使用 CNN 模型進行訓練和測試
        # cross_validation_cnn 函數呼叫 train_and_test_cnn，這裡不需要返回歷史記錄
        accu_test, accu_validation, _, _ = train_and_test_cnn(f_X_train_images, f_Y_train_labels, X_test_images, Y_test_labels,
                                               vali_images, vali_labels)
        print("[*] Temp accuracy of test :", accu_test)
        print("[*] Temp accuracy of validation :", accu_validation)
        tmp_accu_test += accu_test
        tmp_accu_vali += accu_validation

    print("[*] Average accuracy of test :", tmp_accu_test / k)
    print("[*] Average accuracy of validation :", tmp_accu_vali / k)


def main():
    # 讀取數據集
    (x_train, y_train), (x_test, y_test) = mnist.load_data()

    # 訓練集 - 使用 x_train 和 y_train, 並reshape x_train
    total_images = x_train.reshape(x_train.shape[0], -1)  # Reshape to (60000, 784)
    total_labels = y_train
    # 將標籤轉換為 one-hot 編碼
    total_labels = tf_v2.keras.utils.to_categorical(total_labels, num_classes=10)
    total_images, total_labels = shuffer_images_and_labels(total_images, total_labels)

    # 驗證集 - 使用部分訓練集作為驗證集
    validation_images = x_train[:5000].reshape(5000, -1) # Reshape and take first 5000
    validation_labels = y_train[:5000]
    validation_labels = tf_v2.keras.utils.to_categorical(validation_labels, num_classes=10)
    validation_images, validation_labels = shuffer_images_and_labels(validation_images, validation_labels)

    # 簡單劃分訓練集和測試集，進行 CNN 訓練 (這部分是為了演示 CNN 訓練過程和圖表)
    print("簡單劃分訓練集和測試集，進行 CNN 訓練 (演示訓練過程和圖表)")
    train_images_simple = total_images[:50000]
    train_labels_simple = total_labels[:50000]
    test_images_simple = total_images[50000:]
    test_labels_simple = total_labels[50000:]

    # 注意：這裡只呼叫 train_and_test_cnn，它會自己顯示圖表
    accu_test_cnn_simple, accu_validation_cnn_simple, _, _ = train_and_test_cnn(
        train_images_simple, train_labels_simple, test_images_simple, test_labels_simple,
        validation_images, validation_labels)
    print("[*] CNN Accuracy of test (Simple Split):", accu_test_cnn_simple)
    print("[*] CNN Accuracy of validation (Simple Split):", accu_validation_cnn_simple)


    # 顯示前幾個訓練圖像 (使用原始圖像數據，非 one-hot 編碼標籤)
    print("\n顯示訓練圖像：")
    # Re-load data for showing images to use original y_train values
    # 這確保我們顯示的是原始灰度圖像，而不是展平的向量
    (x_train_show, y_train_show), (_, _) = mnist.load_data()
    for i in range(5): # Show first 5 images
        print(f"圖像 {i+1}")
        # show_image function expects flattened, but display needs 28x28
        # 這裡直接使用 matplotlib 顯示 28x28 的原始圖像
        plt.imshow(x_train_show[i], cmap='gray')
        plt.title(f"Label: {y_train_show[i]}") # Display label on the image
        plt.show()

    # 進行交叉驗證 (使用 CNN 模型)
    # 準備用於交叉驗證的數據集 (使用完整的訓練集，但這次使用 hold_out 函數來獲取更均勻的數據分割)
    # 為了演示交叉驗證，我們使用 hold_out 將 total_images 和 total_labels 分割成一個用於交叉驗證的訓練集
    # 以及一個驗證集。這裡選擇用 90% 的數據進行交叉驗證。
    # 請注意：交叉驗證會多次呼叫 train_and_test_cnn，每次訓練一個新的模型。
    # 每次呼叫 train_and_test_cnn 都會顯示一次該折疊的訓練圖表。
    # 如果您不希望看到這麼多圖表，可以在 train_and_test_cnn 中將繪圖部分註釋掉，或者在 cross_validation_cnn 中處理圖表邏輯。
    print("\n[*] Performing Cross Validation (Using CNN model)")
    cv_train_images, cv_train_labels, _, _ = hold_out(total_images, total_labels, 0.9) # Use 90% for CV training set

    # 進行 5 折交叉驗證 (使用 CNN 模型)
    cross_validation_cnn(cv_train_images, cv_train_labels, 5, validation_images, validation_labels)


if __name__ == '__main__':
    main()
